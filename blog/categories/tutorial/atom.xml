<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tutorial | Personal Interview Notes]]></title>
  <link href="http://tdongsi.github.io/python/blog/categories/tutorial/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/python/"/>
  <updated>2019-02-05T01:05:32-08:00</updated>
  <id>http://tdongsi.github.io/python/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python 3 Quick Recap]]></title>
    <link href="http://tdongsi.github.io/python/blog/2017/08/13/python-3-quick-recap/"/>
    <updated>2017-08-13T23:49:57-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2017/08/13/python-3-quick-recap</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: Protocols]]></title>
    <link href="http://tdongsi.github.io/python/blog/2016/09/05/tutorial-protocols/"/>
    <updated>2016-09-05T23:50:24-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2016/09/05/tutorial-protocols</id>
    <content type="html"><![CDATA[<p>Python uses &ldquo;duck typing&rdquo;.
It does not have interfaces like Java to enforce certain behaviors:
<code>Iterable</code> iterface means that you can iterate an object of that class in a <code>for each</code> loop.
In Python, to do that, you have to override magic functions like <code>__iter__</code> to achieve some behaviors.
Each behavior is called &ldquo;protocol&rdquo; in this post since some involves overriding multiple magic funtions.</p>

<!-- Reference:
Evernote: "OOP in Python"
-->




<!--more-->


<h3>Iterator</h3>

<p>Here, <code>__iter__</code> just returns self, an object that has the function next(), which (when called) either returns a value or raises a StopIteration exception.
We’ve actually already met several iterators in disguise; in particular, <code>enumerate</code> is an iterator.
To drive home the point, here’s a simple reimplementation of <code>enumerate</code>:</p>

<pre><code class="python Implement enumerator() as iterator">&gt;&gt;&gt; class my_enumerate:
...   def __init__(self, some_iter):
...      self.some_iter = iter(some_iter)
...      self.count = -1
...
...   def __iter__(self):
...      return self
...
...   def next(self):
...      val = self.some_iter.next()
...      self.count += 1
...      return self.count, val
&gt;&gt;&gt; for n, val in my_enumerate(['a', 'b', 'c']):
...   print n, val
0 a
1 b
2 c
</code></pre>

<h4>Generator and Iterator protocol</h4>

<p>It is also much easier to write routines like enumerate as a generator than as an iterator:</p>

<pre><code class="python Implement enumerate() using generator">&gt;&gt;&gt; def gen_enumerate(some_iter):
...   count = 0
...   for val in some_iter:
...      yield count, val
...      count += 1
</code></pre>

<p>But you can do things with generators that you couldn’t do with finite lists.
Consider two full implementation of Eratosthenes’ Sieve for finding prime numbers.
Full discussion is <a href="http://intermediate-and-advanced-software-carpentry.readthedocs.io/en/latest/idiomatic-python.html">here</a>.
Most of these are from &ldquo;Python tutorial&rdquo;.</p>

<h3>Container</h3>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: Basic Algorithms]]></title>
    <link href="http://tdongsi.github.io/python/blog/2016/09/02/tutorial-basic-algorithms/"/>
    <updated>2016-09-02T01:04:37-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2016/09/02/tutorial-basic-algorithms</id>
    <content type="html"><![CDATA[<p>For sorting algorithms, see <a href="/blog/2016/08/30/tutorial-sorting-algorithms/">this post</a>.</p>

<!--more-->


<h3>Binary search</h3>

<pre><code class="python Binary search">def binary_search(mlist, item):
    """ Binary search

    :param mlist: sorted list in ascending order
    :param item:
    :return: index of item in list. -1 if not found.
    """

    def _bin_search(start, end):
        if start == end:
            # empty
            return -1
        elif start == end-1:
            # singleton
            if mlist[start] == item:
                return start
            else:
                return -1
        else:
            med = (start+end)/2
            if mlist[med] == item:
                return med
            elif mlist[med] &lt; item:
                return _bin_search(med+1, end)
            else:
                return _bin_search(start, med)

    if len(mlist) == 0:
        return -1
    else:
        return _bin_search(0, len(mlist))
</code></pre>

<p>For more advanced binary operations, check <code>bisect</code> module.
Using <code>bisect</code> module for binary search will be awkward and not recommended in an interview.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: More About Quick Sort]]></title>
    <link href="http://tdongsi.github.io/python/blog/2016/08/31/tutorial-more-about-quick-sort/"/>
    <updated>2016-08-31T21:48:49-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2016/08/31/tutorial-more-about-quick-sort</id>
    <content type="html"><![CDATA[<p>This post discuses more about partition algorithms used in Quick Sort and its runtime.
Partition algorithms are also used to efficiently find certain groups of the list, also known as &ldquo;Quick Select&rdquo;.</p>

<!-- more -->


<h3>Discussion of Quick-sort runtime</h3>

<p>The Quick-sort algorithm has a very serious weakness: O(n<sup>2</sup>) runtime in the worst-case scenarios.
Because of this weakness, it should not used in any large-scale applications with arbitrary inputs.
This section discusses when those worst-case scenarios happen and how we can limit the chance of those scenarios.
Before going into details, it should be noted that worst-case scenarios cannot be avoided, and those scenarios depend on the partition strategy that Quick-sort uses.
To find the worst-case scenarios for a partition strategy, find a class of inputs such that after each partition, only one item is moved to either side of the pivot.</p>

<p>In the standard two-way partition strategy (&ldquo;&lt; pivot&rdquo; and &ldquo;>= pivot&rdquo;) shown in <a href="/blog/2016/08/30/tutorial-sorting-algorithms/">this post</a>, it has the O(n<sup>2</sup>) runtime when the input list is sorted (Quiz: in which direction?).
One simple way to work around that problem is to shuffle the input list (by swapping random elements).
Shuffling the list can be done in O(n) time and should has no effect to overall O(nlogn) sorting runtime.</p>

<p>However, even with shuffling, the worst-case scenario happens when the input list has many repeated items.
One way to work around that is to three-way partition as shown below, only proceed with the &ldquo;&lt;&rdquo; and &ldquo;>&rdquo; partitions, and ignoring &ldquo;=&rdquo; partition.
This Quick-sort partition is usually the one used in most libraries and typically very fast in practice.</p>

<h4>Three-way partitions</h4>

<pre><code class="python">def partition3(mlist, lo, hi):
    """ In-place three-way partition of the list will return [&lt; pivot] [== pivot] [&gt; pivot].

    The two-way partition ([&lt; pivot] [&gt;= pivot]) seen in previous quicksort has the following degenerate cases:
     1. Almost sorted lists. -&gt; Defense: Use random swaps to scramble the lists before sorting.
     2. Almost equal items. -&gt; Defense: Use this three-way partition strategy.
    """
    def swap(a, b):
        mlist[a], mlist[b] = mlist[b], mlist[a]

    pidx = random.randint(lo, hi - 1)
    swap(pidx, hi - 1)
    pivot = mlist[hi - 1]

    idx1 = lo
    for i in range(lo, hi - 1):
        if mlist[i] &lt; pivot:
            swap(i, idx1)
            idx1 += 1

    idx2 = idx1
    for i in range(idx1, hi - 1):
        if mlist[i] == pivot:
            swap(i, idx2)
            idx2 += 1

    swap(idx2, hi - 1)

    return idx1, idx2


def quicksort3(mlist, lo=0, hi=None):
    """ Quick-sort using three-way partition strategy.
    """
    if not mlist:
        return mlist

    if hi is None:
        hi = len(mlist)

    if lo == hi:
        # empty list
        return mlist
    elif lo == hi - 1:
        # singleton list
        return mlist
    else:
        p, q = partition3(mlist, lo, hi)
        quicksort3(mlist, lo, p)
        quicksort3(mlist, q + 1, hi)
        return mlist
</code></pre>

<p>A few lessons for learning/interview before arriving at this final version:</p>

<ul>
<li>Separate to two same-level functions <code>quicksort3</code> and helper <code>partition3</code> for easy reading.
Do NOT put <code>partition3</code> as a function inside <code>quicksort3</code>.
It is hard to read on the whiteboard with inconsistent spacing.</li>
<li>Define one-liner <code>swap</code> inside <code>parition3</code> and use it.
It will make to code much easier to read.</li>
<li>Find random pivot: do not settle for <code>mlist[hi-1]</code> pivot.
The interviewers WILL ask anyway.</li>
<li>Use <code>idx1, idx2</code> as variables instead of <code>p, q</code> since it&rsquo;s so easy to mix up <code>p</code> and <code>q</code> in interview context.</li>
</ul>


<h3>Quick Select</h3>

<p>Sometimes, interview questions will involve &ldquo;order statistics&rdquo;, such as finding k-th smallest element in an array.
To do this, you select a random pivot and partition the array as you would in the Quicksort algorithm.
Then, based on the index of the pivot element, you know which half of the array contains the desired element.
For example: k=10 and n=20, if the first half contains 5 elements, then you should ignore the first half, and recursively process the second half with k=4 and n=14.
The runtime of this algorithm is O(n), not O(n log n), since the recursive call is only on one half of the array.</p>

<h4>Find median</h4>

<p>Find median is a special case of finding k-th smallest item.
You still have to implement finding k-th smallest helper function.</p>

<pre><code class="python">def find_median(mlist):
    """ Find the median of a given list of numbers.
    """
    def partition(alist, lo, hi):
        pivot = alist[hi - 1]
        idx = lo

        for i in range(lo, hi-1):
            if alist[i] &lt; pivot:
                alist[i], alist[idx] = alist[idx], alist[i]
                idx += 1
        # move the pivot
        alist[idx], alist[hi - 1] = alist[hi - 1], alist[idx]
        return idx

    def find_kth(mlist, k, lo, hi):
        if lo == hi:
            # empty list
            return None
        elif lo == hi-1:
            # singleton list
            return mlist[lo] if k == lo else None
        else:
            p = partition(mlist, lo, hi)
            if p == k:
                return mlist[p]
            elif p &lt; k:
                return find_kth(mlist, k, p+1, hi)
            else:
                return find_kth(mlist, k, lo, p)
        pass

    length = len(mlist)
    if length == 0:
        return None

    if length % 2 == 1:
        # if odd length
        return find_kth(mlist, length/2, 0, length)
    else:
        # if length is even
        first = find_kth(mlist, length/2-1, 0, length)
        second = find_kth(mlist, length/2, 0, length)
        return (first+second)/2.0
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tutorial: Sorting Algorithms]]></title>
    <link href="http://tdongsi.github.io/python/blog/2016/08/30/tutorial-sorting-algorithms/"/>
    <updated>2016-08-30T21:23:48-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2016/08/30/tutorial-sorting-algorithms</id>
    <content type="html"><![CDATA[<p>Quick overview and implementations of the most common sorting algorithms.</p>

<p>Most updated implementations are in <a href="https://github.com/tdongsi/python/blob/master/CodeJam/practice/y2016/basic.py">this Python module</a>.</p>

<!-- more -->


<h3>Sorting algorithms</h3>

<h4>Overview of space/time complexity</h4>

<table>
<thead>
<tr>
<th> </th>
<th> Time Complexity (Avg/Worst) </th>
<th> Space Complexity </th>
<th> In-place/Stable? </th>
<th> Notes </th>
</tr>
</thead>
<tbody>
<tr>
<td> <strong>Heapsort</strong> </td>
<td>  O(n * log n) / O(n * log n) </td>
<td> O(1) </td>
<td> Yes/No </td>
<td> NA </td>
</tr>
<tr>
<td> <strong>Mergesort</strong> </td>
<td> O(n * log n) / O(n * log n).</td>
<td> O(n) </td>
<td> No/Yes </td>
<td> Space O(1) for doubly-linked list. </td>
</tr>
<tr>
<td> <strong>Quicksort</strong> </td>
<td> O(n * log n) / O(n * n) </td>
<td> O(1) </td>
<td> Yes/No </td>
<td> It is stable for linked-list. </td>
</tr>
<tr>
<td> <strong>Insertion sort</strong> </td>
<td> O(n * n) / O(n * n) </td>
<td> O(1) </td>
<td> Yes/Yes </td>
<td> Adaptive: quick for largely sorted list. Online. Efficient for small lists. </td>
</tr>
<tr>
<td> <strong>Selection sort</strong> </td>
<td> O(n * n) / O(n * n) </td>
<td> O(1) </td>
<td> Yes/No </td>
<td> Adaptive: similar to Insertion Sort. More comparisons. Less write operations. </td>
</tr>
<tr>
<td> <strong>Counting sort</strong> </td>
<td> O(n + k) / O(n + k) </td>
<td> O(1) </td>
<td> ?/? </td>
<td>  Not comparison-sort. For small range. </td>
</tr>
<tr>
<td> <strong>Radix sort</strong> </td>
<td> O(w * n) / O(w * n) </td>
<td> O(1) </td>
<td> Yes/Yes (some variants) </td>
<td>  Not comparison-sort. <em>w -> log n</em> for arbitrary range. </td>
</tr>
</tbody>
</table>


<p><br></p>

<p>Note that <strong>insertion sort</strong> still has its place even though it is not a <code>O(n * log n)</code> algorithm.
It is shown in practice that &ldquo;insertion sort&rdquo; is faster than other sorting algorithms for sufficiently small, mostly sorted lists.
A common application of &ldquo;insertion sort&rdquo; is in <strong>merge sort</strong> implementations where
&ldquo;merge sort&rdquo; calls its own internal &ldquo;insertion sort&rdquo; to sort small enough sub-lists before merging (instead of keeping recursing to singleton lists).</p>

<p><strong>Selection sort</strong> seems inferior to <strong>insertion sort</strong> as an O(n<sup>2</sup>) sorting algorithm in most cases.
However, selection sort will perform identically regardless of the order of the array (almost sorted or unsorted), which can be a plus in real-time application.
While selection sort is preferable to insertion sort in terms of number of writes (Θ(n) swaps versus Ο(n2) swaps), <strong>cycle sort</strong> is the most optimal in &ldquo;number of write&rdquo; metric (write can be expensive in some situations).</p>

<h4>How to approach sorting questions</h4>

<p>Simply using quick-sort for any sorting in algorithmic questions could fail you, since it shows inexperience.
Asking clarifying questions is key: sorting a very large list of integers can have different approach, depending on its input size, data structure, numeric range and distribution.</p>

<ul>
<li>Small range: O(n) with array-based map.</li>
<li>Medium range: O(wn) with radix sort.</li>
<li>Arbitrary number: O(n log n)</li>
</ul>


<p><strong>Example</strong>: &ldquo;Design an algorithm to sort a list&rdquo;.</p>

<ul>
<li>What kind of list? Array list or linked list? Array list.</li>
<li>What data in it? Numbers or characters or strings? Numbers.</li>
<li>Are numbers integers? Yes.</li>
<li>What range of numbers? Are they IDs or values of something? Ages of customers.</li>
<li>How many numbers? One million.</li>
</ul>


<p>Based on the answers above, the best solution is to use an array of size 200 to keep count of customers for a given age.
Size 200 is chosen because the oldest person is less than 200 years old.
You can see that the space and time complexity is much different from Merge-Sort when you know characteristics of input data.</p>

<h3>Merge Sort</h3>

<pre><code class="python">def merge_sort(mlist):
    def _merge(left, right):
        alist = []
        l_idx = 0
        r_idx = 0

        while l_idx &lt; len(left) and r_idx &lt; len(right):
            if left[l_idx] &lt; right[r_idx]:
                alist.append(left[l_idx])
                l_idx += 1
            else:
                alist.append(right[r_idx])
                r_idx += 1

        # append the rest
        alist.extend(left[l_idx:])
        alist.extend(right[r_idx:])

        return alist

    if len(mlist) &lt;= 1:
        return mlist
    else:
        med = len(mlist) // 2
        left = merge_sort(mlist[:med])
        right = merge_sort(mlist[med:])
        return _merge(left, right)
</code></pre>

<h3>Quick Sort</h3>

<p>One important characteristic of Quick Sort is in-place.
Naive implementation tends to ignore this, focusing on its divide-and-conquer strategy.
The standard implementation is as follows, but see <a href="/blog/2016/08/31/tutorial-more-about-quick-sort/">this post</a> for more details.</p>

<pre><code class="python">def quicksort(mlist, lo=0, hi=None):

    def partition(alist, lo, hi):
        pivot = alist[hi - 1]
        idx = lo

        for i in range(lo, hi-1):
            if alist[i] &lt; pivot:
                alist[i], alist[idx] = alist[idx], alist[i]
                idx += 1
        # move the pivot
        alist[idx], alist[hi - 1] = alist[hi - 1], alist[idx]
        return idx


    if hi is None:
        hi = len(mlist)

    if lo == hi:
        # empty list
        return mlist
    elif lo == hi-1:
        # singleton list
        return mlist
    else:
        p = partition(mlist, lo, hi)
        quicksort(mlist, lo, p)
        quicksort(mlist, p+1, hi)
        return mlist
</code></pre>

<h3>Heap Sort</h3>

<p>Straight from <code>heapq</code> module&rsquo;s documentation.</p>

<pre><code class="python">def heap_sort(mlist):
    heapq.heapify(mlist)
    return [heapq.heappop(mlist) for e in range(len(mlist))]
</code></pre>

<h3>Insertion Sort</h3>

<pre><code class="python Insertion sort">def insertion_sort(mlist):
    if len(mlist) &lt;= 1:
        return mlist

    for i in xrange(1, len(mlist)):
        pos = i
        cur = mlist[i]

        while pos &gt; 0 and cur &lt; mlist[pos-1]:
            mlist[pos] = mlist[pos-1]
            pos -= 1
        mlist[pos] = cur

    return mlist
</code></pre>

<h3>Selection sort</h3>

<pre><code class="python Selection sort">def selection_sort(mlist):
    for i in range(0, len(mlist)-1):
        iMin = i
        for j in range(i+1, len(mlist)):
            if mlist[j] &lt; mlist[iMin]:
                iMin = j

        if iMin != i:
            mlist[iMin], mlist[i] = mlist[i], mlist[iMin]

    return mlist
</code></pre>

<h3>Counting Sort</h3>

<p>Based on <a href="https://www.youtube.com/watch?v=Nz1KZXbghj8&amp;t=1925s">this lecture</a>.</p>

<pre><code class="python Counting Sort">def counting_sort(mlist, k=None, key=None):
    """Counting sort

    :param mlist: List of items.
    :param k: Maximum range of key [0,k)
    :param key: function to get key of item. (for radix sort)
    :return:
    """
    if k is None:
        k = max(mlist) + 1

    if key is None:
        key = lambda x: x

    counter = [[] for i in range(k)]
    for i in range(len(mlist)):
        counter[key(mlist[i])].append(mlist[i])

    output = []
    for i in range(k):
        output.extend(counter[i])
    return output
</code></pre>

<h3>Radix Sort</h3>

<p>Use <code>counting_sort</code> in the last section as the subroutine.
See <a href="https://www.youtube.com/watch?v=Nz1KZXbghj8&amp;t=1925s">here</a>.</p>

<pre><code class="python Radix sort">def radix_sort(mlist, w=None):
    RADIX = 10

    # Find the max length
    if w is None:
        temp = max(mlist)
        w = 0
        while temp &gt; 0:
            w += 1
            temp //= RADIX

    output = mlist
    for digit in range(w):
        def my_key(num):
            for _ in range(digit):
                num //= RADIX
            return num % RADIX

        output = counting_sort(output, RADIX, my_key)
        # print(output)

    return output
</code></pre>

<h3>Testing sorting algorithms</h3>

<p>Codes to verify your sorting algorithm.</p>

<pre><code class="python">import your_module.your_sort_impl as do_sort

class TestSorting(unittest.TestCase):

    def test_sort(self):
        # import sorting function as do_sort
        for i in xrange(1, 20):
            # Do it 5 times
            expected = range(i)
            for i in xrange(5):
                mlist = expected[:]
                random.shuffle(mlist)
                # print mlist
                self.assertEqual(do_sort(mlist), expected)

        pass

    def test_same_element(self):

        self.assertEqual(do_sort([2, 3, 5, 7, 4, 2, 6, 1]), [1, 2, 2, 3, 4, 5, 6, 7])
        self.assertEqual(do_sort([2, 2]), [2, 2])
        self.assertEqual(do_sort([1, 2, 1]), [1, 1, 2])
        self.assertEqual(do_sort([2, 3, 1, 2, 2, 4, 3, 1]), [1, 1, 2, 2, 2, 3, 3, 4])
        self.assertEqual(do_sort([2, 1]), [1, 2])
        pass
</code></pre>
]]></content>
  </entry>
  
</feed>
