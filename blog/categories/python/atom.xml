<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Personal Interview Notes]]></title>
  <link href="http://tdongsi.github.io/python/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://tdongsi.github.io/python/"/>
  <updated>2019-02-13T00:04:45-08:00</updated>
  <id>http://tdongsi.github.io/python/</id>
  <author>
    <name><![CDATA[Cuong Dong-Si]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Effective Python Pt. 6: Robust Programs]]></title>
    <link href="http://tdongsi.github.io/python/blog/2018/12/16/effective-python-part-6/"/>
    <updated>2018-12-16T17:58:58-08:00</updated>
    <id>http://tdongsi.github.io/python/blog/2018/12/16/effective-python-part-6</id>
    <content type="html"><![CDATA[<p>This post corresponds to Lesson 6 &ldquo;Making Programs Robust&rdquo; of <a href="https://www.safaribooksonline.com/videos/effective-python/9780134175249">&ldquo;Effective Python&rdquo; course</a>.</p>

<p>NOTE: While the book is about Python 3, my blog checks out its application in Python 2.</p>

<!--more-->


<h3>Item 28: Use virtualenv</h3>

<p>Use <code>pip</code> commands for virtual environment management.</p>

<pre><code class="plain">
$ pip show flask
Name: Flask
Version: 1.0.2
Summary: A simple framework for building complex web applications.
Home-page: https://www.palletsprojects.com/p/flask/
Author: Armin Ronacher
Author-email: armin.ronacher@active-4.com
License: BSD
Location: /Users/tdongsi/Matrix/python/venv/lib/python2.7/site-packages
Requires: Werkzeug, click, Jinja2, itsdangerous
Required-by:

$ pip install --upgrade Jinja2
Requirement already up-to-date: Jinja2 in ./venv/lib/python2.7/site-packages (2.10)
Requirement already satisfied, skipping upgrade: MarkupSafe&gt;=0.23 in ./venv/lib/python2.7/site-packages (from Jinja2) (1.1.0)

$ pip list
Package                  Version
------------------------ ----------
alabaster                0.7.12
Babel                    2.6.0
certifi                  2018.11.29
chardet                  3.0.4
Click                    7.0
...

$ pip freeze
alabaster==0.7.12
Babel==2.6.0
certifi==2018.11.29
chardet==3.0.4
Click==7.0
...

$ pip freeze &gt; requirements.txt

# In another virtualenv
$ pip install -r requirements.txt
</code></pre>

<p>Set up and use virtual environment in Python 2.</p>

<pre><code class="plain">
# Create new virtual env
$ virtualenv venv
New python executable in /Users/tdongsi/Matrix/python/venv/bin/python
Installing setuptools, pip, wheel...
done.

# Activate new virual env
$ source venv/bin/activate

$ deactivate
</code></pre>

<h4>Python 3</h4>

<p>The difference in Python 3 is the dedicated command <code>pyvenv</code> and no separate installation of <code>virtualenv</code> is required.</p>

<pre><code class="plain virtualenv in Python 3">$ pyvenv -h

# Create new virtual env
$ pyvenv myproject

# Activate new virual env
$ source myproject/bin/activate

$ deactivate
</code></pre>

<h3>Item 29: Tests with unittest</h3>

<p>Tests are even more important in Python (than Java) since it is a dynamic language.
<code>unittest</code> module can be used for both unit tests (isolated tests) and functional/integration tests (verifying interactions).</p>

<pre><code class="python unittest examples">from unittest import TestCase

class ExampleTest(TestCase):

    def setUp(self):
        print('Setup')

    def tearDown(self):
        print('Teardown')

    def test_a(self):
        print('a')

    def test_b(self):
        print('b')


if __name__ == '__main__':
    unittest.main()
</code></pre>

<h3>Item 30: Debugging with <code>pdb</code></h3>

<pre><code class="python Use debugger"># Code before
import pdb; pdb.set_trace()
# Code after
</code></pre>

<p>A few debugger commands when you are already in the debugger:</p>

<pre><code class="plain">next
step
locals()
bt  # back trace
up
down
</code></pre>

<p>The Python debugger <code>pdb</code> is very similar to C debugger in Linux.
However, you are probably better off with debugger in proper IDEs such as PyCharm with better visualization.</p>

<h3>Iten 31: Profile before optimizing</h3>

<p>In summary, how to do CPU profiling in Python.</p>

<p>Dynamic nature of Python programs can lead to surprising performance impact.
Profiling is easy to do in Python with built-in modules, as shown below, and allows us to focus on measurable sources of performance bottlenecks.</p>

<pre><code class="python Profiling in Python">from cProfile import Profile
from pstats import Stats

profiler = Profile()
# profiler.runcall(insertion_sort, data)
profiler.runcall(lambda: insertion_sort(data))

stats = Stats(profiler)
stats.strip_dirs()
stats.sort_stats('cumulative')
stats.print_stats()
</code></pre>

<pre><code class="plain Profiler output">         20003 function calls in 0.791 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.791    0.791 item31.py:27(&lt;lambda&gt;)
        1    0.002    0.002    0.791    0.791 item31.py:7(insertion_sort)
    10000    0.780    0.000    0.789    0.000 item31.py:14(insert_value)
     9989    0.010    0.000    0.010    0.000 {method 'insert' of 'list' objects}
       11    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
</code></pre>

<p>Another print method <code>stats.print_callers()</code> can reorganize the same information in a different way.</p>

<pre><code class="plain">   Ordered by: cumulative time

Function                                          was called by...
                                                      ncalls  tottime  cumtime
item31.py:25(&lt;lambda&gt;)                            &lt;-
item31.py:8(insertion_sort)                       &lt;-       1    0.002    0.023  item31.py:25(&lt;lambda&gt;)
item31.py:15(insert_value)                        &lt;-   10000    0.004    0.021  item31.py:8(insertion_sort)
{method 'insert' of 'list' objects}               &lt;-   10000    0.011    0.011  item31.py:15(insert_value)
{_bisect.bisect_left}                             &lt;-   10000    0.006    0.006  item31.py:15(insert_value)
{method 'disable' of '_lsprof.Profiler' objects}  &lt;-
</code></pre>

<p>More details can be found in <a href="https://docs.python.org/2/library/profile.html">Python documentation</a>.</p>

<h3>Item 32: Use tracemalloc to undertand memory usage and leaks</h3>

<p>In summary, this item is about how to do memory profiling in Python.</p>

<p>Python has automatic garbage collection: reference counting and cycle detection for looping references.
Despite that, memory leaks still happen and it&rsquo;s hard in practice to figure out why references are held.</p>

<pre><code class="python gc module">import gc

found_objects = gc.get_objects()
print('%d objects before' % len(found_objects))

import waste_memory
x = waste_memory.run()

found_objects = gc.get_objects()
print('%d objects after' % len(found_objects))
</code></pre>

<p><code>gc</code> module allows you to interact with garbage collectors and take a look into how many objects created, as shown above.
However, such information is usually not enough to figure out what went wrong: objects of the same class can be created in various ways.
You need more information to figure out where the allocation and the memory leak happens.</p>

<p>In Python 3, we have <code>tracemalloc</code> module that allows comparing between two memory snapshots and trace back to the code lines where such memory allocations happen.
See <a href="https://pytracemalloc.readthedocs.io/examples.html">more examples</a>.
For Python 2.7, it is not part of the Standard Library.
Therefore, we have to patch and compile Python 2.7 to use the 3rd party <code>pytracemalloc</code> module.
The instructions to do it can be found in <a href="http://carsonip.me/posts/debugging-memory-usage-python-tracemalloc/">here</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Effective Python Pt. 5: Concurrency and Parallelism]]></title>
    <link href="http://tdongsi.github.io/python/blog/2018/08/18/effective-python-pt-5-concurrency-and-parallelism/"/>
    <updated>2018-08-18T16:24:30-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2018/08/18/effective-python-pt-5-concurrency-and-parallelism</id>
    <content type="html"><![CDATA[<p>This post corresponds to Lesson 5 &ldquo;Concurrency and Parallelism&rdquo; of <a href="https://www.safaribooksonline.com/videos/effective-python/9780134175249">&ldquo;Effective Python&rdquo; course</a>.</p>

<!--more-->


<h3>Item 23: Use subprocess to manage child processes</h3>

<pre><code class="python Typical usage of subprocess module">import subprocess

proc = subprocess.Popen(
    ['echo', 'Hello World'],
    stdout=subprocess.PIPE
)
out, err = proc.communicate()
print(out.decode('utf-8'))
</code></pre>

<pre><code class="python Simple forking example">proc = subprocess.Popen(['sleep', '0.3'])
while proc.poll() is None:
    print('Working...')
    # Time consuming process
    time.sleep(0.2)

print('Exit status: %d' % proc.poll())
</code></pre>

<p>In the forking example above, note that <code>proce.poll()</code> is used to check for and obtain the status of the child process.</p>

<pre><code class="python Parallelism wtih subprocess">def run_sleep(period):
    proc = subprocess.Popen(['sleep', str(period)])
    return proc


start = time.time()
procs = []
for _ in range(10):
    proc = run_sleep(0.3)
    procs.append(proc)

for proc in procs:
    proc.communicate()

end = time.time()
print('Takes %f seconds' % (end - start))
</code></pre>

<p>In the parallisim example above, the time it takes is approximately 0.3 seconds, no matter how many processes you create.</p>

<pre><code class="python Piping data from Python data to subprocess"># You can pipe data from Python program to subprocess
# In this way, you can call other programs to run in parallel with Python process.
# Run sub-processes on multiple CPUs.
def run_openssl(data):
    """A computing-intensive method, best for running separately on separate CPUs."""
    env = os.environ.copy()
    env['password'] = b'asdf'
    proc = subprocess.Popen(
        ['openssl', 'enc', '-des3', '-pass', 'env:password'],
        env=env,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE
    )
    proc.stdin.write(data)
    proc.stdin.flush()
    return proc

procs = []
for _ in range(5):
    data = os.urandom(100)
    proc = run_openssl(data)
    procs.append(proc)

for proc in procs:
    out, _ = proc.communicate()
    print(out)
</code></pre>

<p>Note that in this piping example above, you can use <code>os.environ.copy</code> to shield current process&rsquo;s environment from modifications of its variables.
You can use the new copy of environment by specifying <code>env=my_env</code> in <code>Popen</code> constructor.
In addition, you can use the environment variable as parameters in the <code>Popen</code> command by using <code>env:password</code>.
To pipe data from Python into the subprocess, you need to set <code>stdin=subprocess.PIPE</code> and transfer data by using <code>proc.stdin.write(data)</code>.</p>

<pre><code class="python Subprocess timeout in Python 3"># Python 3 way
proc = subprocess.Popen(['sleep', '10'])
try:
    proc.communicate(timeout=0.1)
except subprocess.TimeoutExpired:
    proc.terminate()
    proc.wait()

print('Exit status', proc.poll())
</code></pre>

<p>It&rsquo;s not available in Python 2, and if you want to reproduce its functionality in Python 2, you actually have to use the <code>select</code> module and poll the input and output file descriptors of the subprocess.
It is a little bit more complicated and it&rsquo;s hard to get right.</p>

<pre><code class="python Stop-gap alternative in Python 2">class Command(object):
    """ Stop-gap alternative for subprocess's timeout in Python 3.
    Based on https://stackoverflow.com/questions/1191374/using-module-subprocess-with-timeout
    """

    def __init__(self, process):
        self.process = process

    def run(self, timeout):
        def target():
            self.process.communicate()

        thread = threading.Thread(target=target)
        thread.start()

        thread.join(timeout)
        if thread.is_alive():
            print 'Terminating process'
            self.process.terminate()
            thread.join()

        print(self.process.returncode)

proc = subprocess.Popen(['sleep', '2'])
command = Command(proc)
command.run(timeout=3)

# NOTE: the following will not work since the subprocess already ran.
# command = Command(proc)
command = Command(subprocess.Popen(['sleep', '2']))
command.run(timeout=1)
</code></pre>

<h3>Item 24: Use threads for blocking I/O, NOT for parallelism</h3>

<p>Python has the GIL, or Global Interpreter Lock.
It means that only one Python thread will ever actually run at a time.
A common mistake is to use threads to speed up a computation-intensive program in Python.
You will be usually disappointed and end up with similar, if not worse, performance.
In other words, you might find that your complicated parallel version will have similar performance as the serial one.</p>

<p>In Python, threads are good for two main use cases.
The first use case is, if you want something looks running simultaneously (concurrency).
A common example is to respond to user inputs while doing network I/O.
In this case, the threads will cooperate with each other to obtain GIL fairly.
The second use case for threads in Python is for IO-intensive applications such as those with lots of (blocking) network, system calls.
A common example is to use threads to query multiple REST endpoints concurrently.
The following example illustrate such use case:</p>

<pre><code class="python Use Python threads for network I/O">import threading
import requests
import time

def get_response(url):
    r = requests.get(url)
    return r.status_code, r.text

class RequestThread(threading.Thread):

    def __init__(self, url):
        super(RequestThread, self).__init__()
        self._url = url

    def run(self):
        self.output = get_response(self._url)

urls = ['https://www.google.com',
        'https://www.facebook.com',
        'https://www.apple.com',
        'https://www.netflix.com',
        'https://www.salesforce.com',
        'https://www.intuit.com',
        'https://www.amazon.com',
        'https://www.uber.com',
        'https://www.lyft.com']

threads = []
for url in urls:
    thread = RequestThread(url)
    thread.start()
    threads.append(thread)

for thread in threads:
    thread.join()
</code></pre>

<p>TODO: Explain GIL and under the cover, <code>request</code> release the control of GIL.</p>

<p>TODO: mistake</p>

<p>TODO: Note about how to call constructor.</p>

<h3>Item 26: Use Queue to cordinate work between threads</h3>

<p>Queue as the blocking queue for threads.</p>

<p>ClosableQueue and Woker classes for building pipelines of workers running in parallel and coordination.</p>

<h3>Item 27: concurrent.futures for true parallelism</h3>

<p><code>ProcessPoolExecutor</code> as the high level API to split work into subprocesses.</p>

<p>Explanation of works behind the scene: lots of serialization and deserialization between main process and child processes.</p>

<p>When to use multiprocessing:</p>

<ul>
<li>Isolated: no data sharing.</li>
<li>High leverage: small input data, large computation.</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Effective Python Pt. 4: Using Classes]]></title>
    <link href="http://tdongsi.github.io/python/blog/2018/08/12/effective-python-part-4/"/>
    <updated>2018-08-12T00:19:36-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2018/08/12/effective-python-part-4</id>
    <content type="html"><![CDATA[<p>This post corresponds to Lesson 4 &ldquo;Using Classes&rdquo; of <a href="https://www.safaribooksonline.com/videos/effective-python/9780134175249">&ldquo;Effective Python&rdquo; course</a>.</p>

<!--more-->


<h3>Item 19: Prefer helper classes over book-keeping with dict and tuples</h3>

<p>In an example, the author illustrated the progressive evolution of a grade-book application.
In each iteration, the requirements are changed and interfaces are changed to accomodate that.
Consequently, dictionaries and tuples are added to accomodate those changes in implementation but the logic and code becomes so convoluting with all book-keeping with those built-int data structures.
The final version is shown as follows:</p>

<pre><code class="python Original code with dicts and tuples">class WeightedGradebook(object):
    """
    Change WeightedGradebook to make the score in each subject is weighted.
    For example, final is more weighted than homework.
    """

    def __init__(self):
        self._grade = {}

    def add_student(self, name):
        self._grade[name] = {}

    def report_grade(self, name, subject, score, weight):
        by_subject = self._grade[name]
        grade_list = by_subject.setdefault(subject, [])
        grade_list.append((score, weight))

    def average_grade(self, name):
        by_subject = self._grade[name]
        total, count = 0.0, 0

        for grades in by_subject.values():
            subject_total, subject_weight = 0.0, 0
            for score, weight in grades:
                subject_total = score * weight
                subject_weight = weight

            total += subject_total / subject_weight
            count += 1

        return total / count


def main_weighted():
    book = WeightedGradebook()
    book.add_student('Isaac')

    book.report_grade('Isaac', 'Math', 90, 0.90)
    book.report_grade('Isaac', 'Math', 85, 0.10)
    book.report_grade('Isaac', 'Gym', 95, 0.20)
    book.report_grade('Isaac', 'Gym', 80, 0.20)

    print(book.average_grade('Isaac'))
</code></pre>

<p>As you can see, the <code>average_grade</code> internal implementation is really complicated and hard to understand because of the nested dictionaries.
Externally, the class is not easy to use for clients with four positional arguments: it is easy to mix up the order of arguments, such as weight <code>0.90</code> with score <code>90</code>.</p>

<p>In those cases, it is recommended to unpack dictionaries into separate classes.
Tuples can be unpack into simple classes using <code>namedtuples</code> from <code>collections</code> module.
The line count may be much larger but it is worth it because 1) internally, implementation can be much easier to understand 2) externally, interface can be easier to use.</p>

<pre><code class="python Use helper classes">class Score(object):
    """Weighted score."""

    def __init__(self, score, weight):
        self.score = score
        self.weight = weight

    def weighted_score(self):
        return self.score * self.weight


class Subject(object):
    """Keeping track of weighted scores for a subject"""

    def __init__(self):
        self._grades = []

    def add_score(self, score, weight):
        self._grades.append(Score(score, weight))

    def average_score(self):
        total = sum(e.weighted_score() for e in self._grades)
        weight = sum(e.weight for e in self._grades)
        return total / weight


class Student(object):
    """Keeping track of subjects for a student"""

    def __init__(self):
        self._subjects = defaultdict(Subject)

    def subject(self, name):
        return self._subjects[name]

    def average_grade(self):
        """ Average grade over all subjects"""
        count = len(self._subjects)
        total = sum(e.average_score() for e in self._subjects.values())
        return total / count


class ClassGradebook(object):
    """
    Change WeightedGradebook to make the score in each subject is weighted.
    For example, final is more weighted than homework.
    """

    def __init__(self):
        self._book = defaultdict(Student)

    def student(self, name):
        return self._book[name]

    def report_grade(self, name, subject, score, weight):
        student = self._book[name]
        student.subject(subject).add_score(score, weight)

    def average_grade(self, name):
        student = self._book[name]
        return student.average_grade()

def main_class_2():
    """Helper classes help easier-to-use interface"""
    book = ClassGradebook()

    isaac = book.student('Isaac')
    math = isaac.subject('Math')
    math.add_score(90, 0.90)
    math.add_score(85, 0.10)
    gym = isaac.subject('Gym')
    gym.add_score(95, 0.20)
    gym.add_score(80, 0.20)

    print(isaac.average_grade())
    # Equivalent to the old interface
    print(book.average_grade('Isaac'))
</code></pre>

<h3>Item 20: Use plain attributes instead of getter and setter methods</h3>

<p>For people migrating to Python from Java, they tend to explicit create getter and setter methods for every single attribute in the class.
In Python, it is not recommended and plain attributes should be directly used.</p>

<p>The reason that most people use setters and getters in Java is that in case of changes required for getting or setting an attribute, they can do it easily in corresponding setter or getter method.
In Python, such cases are covered in <code>@property</code> and <code>@setter</code> decorators.</p>

<p>For example, we have the following simple class:</p>

<pre><code class="python Simple class">class Resistor(object):

    def __init__(self, ohms):
        self.ohms = ohms

def main():
    res = Resistor(1e3)
    print(res.ohms)
    res.ohms += 2e3
    print(res.ohms)
</code></pre>

<p>Let&rsquo;s say at some point, we decide that we need special behaviors in getting and setting attribute <code>ohms</code> of Resistor objects.
In that case, we can easily add special behaviors (for example, printing message) as follows:</p>

<pre><code class="python Getter and setter with special behaviors">class Resistor(object):

    def __init__(self, ohms):
        self._ohms = ohms

    @property
    def ohms(self):
        print('Getter')
        return self._ohms

    @ohms.setter
    def ohms(self, value):
        print('Setter')
        self._ohms = value
</code></pre>

<p>The same <code>main()</code> method above will now have the following output:</p>

<pre><code class="plain Before and after output"># Before
1000.0
3000.0

# After
Getter
1000.0
Getter
Setter
Getter
3000.0
</code></pre>

<p>Note that such setter is also effective when the attribute is set in parent constructor, as shown in example below.
This ensures that any validation check in <code>setter</code> method for the attribute is also active at initialization of that object.</p>

<pre><code class="python Setter activated in parent constructor">class Resistor(object):

    def __init__(self, ohms):
        self.ohms = ohms


class LoudResistor(Resistor):

    def __init__(self, ohms):
        super(LoudResistor, self).__init__(ohms)

    @property
    def ohms(self):
        print('Getter')
        return self._ohms

    @ohms.setter
    def ohms(self, value):
        print('Check value')
        self._ohms = value

def main():
    # This will print "Check value"
    # Setter in subclass LoudResistor is activated 
    # although "ohms" attribute is set in superclass Resistor
    res2 = LoudResistor(1e3)
</code></pre>

<p>Tips:</p>

<ul>
<li>Do not modify internal states/attributes or any side effect in getter methods. Only change object&rsquo;s state in setter methods.</li>
<li>Getter method should be fast. Avoid doing complex computations in getter methods.</li>
<li>You can use <code>setter</code> to create unmodifiable objects in Python. See <a href="https://github.com/tdongsi/effective_python">here</a>.</li>
</ul>


<h3>Item 21: Prefer internal attributes over private ones</h3>

<p>In Python, there are only two types of attribute: public (e.g., <code>my_att</code>) and private attributes (e.g., <code>__my_att</code>).
In reality, there is no tight access control like other languages such as Jaza.
The private attribute names are prefixed with the class name (e.g., <code>_MyClass__my_att</code>) to create another &ldquo;namespace&rdquo; for private attributes.
This will complicate accessing the private attributes in the subclasses while not effectively preventing anyone from accessing the private attributes when the need arises.
In general, it is better to use protected/&ldquo;internal&rdquo; attributes <code>_my_att</code> with the assumption that someone can extend usage of those internal attributes later on.</p>

<p>The scenario where you should use private attributes is when you want to avoid accidental name clash in the subclass.</p>

<pre><code class="python Scenario for using private attribute">class ApiClass(object):

    def __init__(self):
        self._value = 5

    def get(self):
        return self._value


class Child(ApiClass):

    def __init__(self):
        super(Child, self).__init__()

        # Here, Child class author is not aware of
        # internal implementation of ApiClass
        # he accidentally override an internal attribute of ApiClass
        self._value = 'hello'

a = Child()
print(a.get())
</code></pre>

<p>In this case, <code>_value</code> in ApiClass should be a private attribute.</p>

<h3>Item 22: Use <code>@classmethod</code> polymorphism to construct objects generically</h3>

<p>In other languages such as Java, you can have overloaded constructors to construct objects of the same class/interface in different ways.
However, in Python, the method <code>__init__</code> can&rsquo;t be overloaded.
Instead, you can use <code>@classmethod</code> polymorphism to construct objects generically.</p>

<pre><code class="python Example of @classmethod polymorphism">import os
from threading import Thread


class InputData(object):
    def read(self):
        raise NotImplementedError

    @classmethod
    def generate_inputs(cls, config):
        raise NotImplementedError


class PathInputData(InputData):

    def __init__(self, path):
        self.path = path

    def read(self):
        with open(self.path, 'rb') as handle:
            return handle.read()

    @classmethod
    def generate_inputs(cls, config):
        """ Generic version of generate_inputs"""
        data_dir = config['data_dir']
        for name in os.listdir(data_dir):
            yield cls(os.path.join(data_dir, name))


def generate_inputs(data_dir):
    """ Original version of generate_inputs"""
    for name in os.listdir(data_dir):
        yield PathInputData(os.path.join(data_dir, name))


class Worker(object):
    def __init__(self, input_data):
        self.input_data = input_data
        self.result = None

    def map(self):
        raise NotImplementedError

    def reduce(self):
        raise NotImplementedError

    @classmethod
    def create_workers(cls, input_class, config):
        """ Generic version of create_worker.

        :param input_class: class that implements InputData interface.
        :param config: dictionary of configs to be used by InputData.
        :return:
        """
        workers = []
        for input_data in input_class.generate_inputs(config):
            workers.append(cls(input_data))
        return workers


def create_worker(input_list):
    """ Original version of create_worker"""
    workers = []
    for input_data in input_list:
        workers.append(LineCounter(input_data))
    return workers


class LineCounter(Worker):
    def map(self):
        data = self.input_data.read()
        self.result = data.count(b'\n')
        pass

    def reduce(self, other):
        self.result += other.result
        pass


def execute(workers):
    threads = [Thread(target=w.map) for w in workers]

    for t in threads:
        t.start()
    for t in threads:
        t.join()

    first, rest = workers[0], workers[1:]
    for other in rest:
        first.reduce(other)
    return first.result


def mapreduce(data_dir):
    inputs = generate_inputs(data_dir)
    workers = create_worker(inputs)
    return execute(workers)


def mapreduce_generic(worker_class, input_class, config):
    workers = worker_class.create_workers(input_class, config)
    return execute(workers)


import random
from backports.tempfile import TemporaryDirectory


def write_test_files(temp_dir):
    for i in range(100):
        with open(os.path.join(temp_dir, str(i)), 'w') as handle:
            handle.write('\n' * random.randint(0, 100))


with TemporaryDirectory() as temp_dir:
    write_test_files(temp_dir)
    # line_count = mapreduce(temp_dir)

    config = {'data_dir': temp_dir}
    line_count = mapreduce_generic(LineCounter, PathInputData, config)
    print line_count
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Effective Python Pt. 3: Functions]]></title>
    <link href="http://tdongsi.github.io/python/blog/2018/08/12/effective-python-part-3/"/>
    <updated>2018-08-12T00:19:32-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2018/08/12/effective-python-part-3</id>
    <content type="html"><![CDATA[<p>This post corresponds to Lesson 3 &ldquo;Using Functions&rdquo; of <a href="https://www.safaribooksonline.com/videos/effective-python/9780134175249">&ldquo;Effective Python&rdquo; course</a>.</p>

<!--more-->


<h3>Item 13: Know how closures interact with variable scope</h3>

<p>For this item&rsquo;s discussion, let&rsquo;s say that we have a list of integers that needs to be sorted, with the twist that some of those integers are in a special group (higher prirority) and has to be placed in front of the list (referred as <strong>Problem-1</strong>).
For example, those integers could be IDs of different UI components, with those of higher priority belong to the foreground and the rest are in the background.
One solution to this problem is as follows:</p>

<pre><code class="python Solution to Problem-1">NUMBERS = [8, 3, 1, 2, 5, 4, 7, 6]
GROUP = {2, 3, 5, 7}

def sort_priority(numbers, group):
    """ Sort the input numbers but put those in "group" first.

    :param numbers: list of input numbers.
    :param group: set of numbers in priority group.
    """

    def helper(x):
        if x in group:
            return (0, x)
        return (1, x)

    numbers.sort(key=helper)
    pass

def main_original():
    numbers = NUMBERS[:]
    print(sort_priority(numbers, GROUP))
    print(numbers)
</code></pre>

<p>Now, the <strong>additional requirement</strong> is that we want to know if any item in the input list belongs to the special <code>GROUP</code> (now referred as <strong>Problem-2</strong>).
To accommodate this new requirement, one can naively modify Problem-1&rsquo;s solution as follows:</p>

<pre><code class="python Naive solution to Problem-2">def sort_priority(numbers, group):
    """ Sort the input numbers but put those in "group" first.

    :param numbers: list of input numbers.
    :param group: set of numbers in priority group.
    :return: True if any number in priority is found.
    """
    found = False

    def helper(x):
        if x in group:
            found = True
            return (0, x)
        return (1, x)

    numbers.sort(key=helper)
    return found
</code></pre>

<p>In this naive (and incorrect) solution, an additional variable <code>found</code> is used to track if any element in the input list <code>numbers</code> is special and set accordingly.
However, this solution proves not working as expected: the above <code>sort_priority</code> method always returns <code>False</code>, regardless of the input list of numbers.</p>

<p>The reason for this is a common mistake of Python users when using the same variable in different scopes.
In this example, <code>found</code> is found in two different scopes: in the enclosed <code>helper</code> method and in the enclosing <code>sort_priority</code> method.
In most cases, when we simply refer to a variable (i.e., read operation), Python will do its best to look up for that variable in different scopes, as shown below.</p>

<pre><code class="python Variable reference in different scopes.">meep = 23

def enclosing():
    """ Variable reference in different scopes.
    """
    foo = 15

    def my_func():
        bar = 10

        print(bar)      # local scope
        print(foo)      # enclosing scope
        print(meep)     # global scope
        print(str)      # built-in scope
        # print(not_exist)  # not found in any scopes

    my_func()

enclosing()

# Output:
# 10
# 15
# 23
# &lt;type 'str'&gt;
</code></pre>

<p>However, variable assignment has a slightly different treatment.
When we try to assign to a variable for the first time in the inner scope, Python will create a new local variable.
This will lead to subtle difference if we have variable assignment in the inner scope, as shown in the following example.</p>

<pre><code class="python Variable assignment in different scopes.">def enclosing_assignment():
    """ Variable assignment in different scopes.
    """

    foo = 15
    foo = 25

    def my_func():
        foo = 15
        bar = 5

        print(foo)
        print(bar)

    my_func()
    print(foo)

enclosing_assignment()

# Output:
# 15
# 5
# 25
</code></pre>

<p>Going back to our Problem-2, the problem of our naive solution is that we have assignment to the variable <code>found</code> in the inner scope.
Python will create a new variable in <code>helper</code>&rsquo;s scope and ignore the variable <code>found</code> already defined in the outer scope <code>sort_priority</code>.
After <code>helper</code> method is done, <code>found</code> in <code>sort_priority</code> scope still has the original value <code>False</code> and it is what the method returns.</p>

<p>There are many ways to work around the scope problem with variable assignment described above.
In Python 3, <code>nonlocal</code> keyword is introduced exactly for this situation.
The keyword <code>nonlocal</code>, similar to <code>global</code> keyword, allows you to assign to variables in outer, but non-global, scope.</p>

<pre><code class="python Using nonlocal keyword for Problem-2">def sort_priority_python_3(numbers, group):
    """ Sort the input numbers but put those in "group" first."""
    found = False

    def helper(x):
        if x in group:
            nonlocal found
            found = True
            return (0, x)
        return (1, x)

    numbers.sort(key=helper)
    return found
</code></pre>

<p>However, using <code>nonlocal</code> keyword can be confusing and is generally not recommended, especially if the variable is declared a couple of scopes/layers away from the assignment.
In addition, such approach would not work in Python 2.
In another approach that would work for both Python 2 and 3, one can use the following trick:</p>

<pre><code class="python Using array for Problem-2">def sort_priority_python_2(numbers, group):
    """ Sort the input numbers but put those in "group" first."""
    found = [False]

    def helper(x):
        if x in group:
            found[0] = True
            return (0, x)
        return (1, x)

    numbers.sort(key=helper)
    return found[0]
</code></pre>

<p>In this trick, instead of using a boolean variable <code>found</code>, you use a singleton (one-element) array <code>found</code>.
Because <code>found</code> is now an array, the variable reference rules, instead of variable assignment rules, apply and the <code>found</code> variable in the outer scope is used.
Although it is a great trick, such code is not really clear.</p>

<p>The final and recommended solution is to extract the <code>helper</code> function into a CheckSpecial class instead.
The original <code>helper</code> method used for <strong>Problem-1</strong> can be converted to a Helper/CheckSpecial class as follows:</p>

<pre><code class="python Using CheckSpecial class for Problem-1">class CheckSpecial(object):

    def __init__(self, group):
        self.group = group

    def __call__(self, x):
        if x in self.group:
            return (0, x)
        return (1, x)

def sort_priority_solved(numbers, group):
    helper = CheckSpecial(GROUP)
    numbers.sort(key=helper)
</code></pre>

<p>In the solution to starting <strong>Problem-1</strong> shown above, the origial <code>helper</code> function&rsquo;s logic has been encapsulated into a CheckSpecial class, in the <code>__call__</code> method specifically.
When the additional requirement &ldquo;check if special number encountered&rdquo; comes in, it is apparent that <code>helper</code> function has to become a stateful closure.
Since we already has it converted to <code>CheckSpecial</code> class, it would be easier to keep the state as a new <code>CheckSpecial</code> object&rsquo;s attribute <code>found</code> and update the object state accordingly, as follows:</p>

<pre><code class="python Updating CheckSpecial class for Problem-2">class CheckSpecial(object):

    def __init__(self, group):
        self.group = group
        self.found = False

    def __call__(self, x):
        if x in self.group:
            self.found = True
            return (0, x)
        return (1, x)

def sort_priority_solved(numbers, group):
    helper = CheckSpecial(GROUP)
    numbers.sort(key=helper)
    return helper.found
</code></pre>

<p>IMHO, this approach is much clearer and works for both Python 2 and 3.</p>

<h3>Item 14: Accept callables for stateful closures</h3>

<p>Many of Python APIs allow you to customize behavior by passing in a function, such as <code>sort(key=...)</code> method in the last section &ldquo;Item 13&rdquo;.
We also see that it is possible to pass stateful closure as a function into those hooks for record-keeping purposes, for example.
We showed different ways to do that in Python 2 and 3: <code>nonlocal</code> keyword, <code>list</code> trick, and a helper class.
Using a class to encapsulate a stateful closure is the highly recommended approach.</p>

<pre><code class="python Another version of CheckSpecial class for Problem-2">class CheckSpecial(object):

    def __init__(self, group):
        self.group = group
        self.found = False

    def check(self, x):
        if x in self.group:
            self.found = True
            return (0, x)
        return (1, x)

def sort_priority_solved(numbers, group):
    helper = CheckSpecial(GROUP)
    numbers.sort(key=helper.check)
    return helper.found
</code></pre>

<p>Let us consider an alternative version of CheckSpecial class where we use standard method name <code>check</code> instead of special method <code>__call__</code>.
And it works perfectly fine if you pass <code>helper.check</code> as a function: <code>sort</code> has no idea that we are passing a method of a stateful object and it does not care.</p>

<p>However, for programmers new to the code, the <code>CheckSpecial</code> class is really awkward: it is not clear the purpose of the class in isolation and that its instances are never to be created and used alone.
Instead, in the last section, we intentionally use <code>__call__</code> method to make each CheckSpecial instance a stateful &ldquo;callable&rdquo;.
In that way, the intention of the class is clearer: it is a stateful closure that is meant to be passed into the hook of another function (e.g., <code>sort</code>, <code>defaultdict</code>).</p>

<h3>Item 15: Reduce visual noise with variable positional arguments</h3>

<pre><code class="python Example of variable position arguments">def log(message, *args):
    pass

log('Check', 1, 2, 3)
args = [1, 2, 3]
log('Check', *args)
</code></pre>

<p>Two things to watch for when using variable positional arguments:</p>

<ul>
<li>If a generator is passed in, the generator will be exhausted as the arguments.</li>
<li>When you change the signature/behavior of the method such as adding new argument in front, it can misbehave quietly.</li>
</ul>


<h3>Item 16: Provide optional behavior with keyword arguments</h3>

<p>Positional arguments come before keyword arguments.
You can&rsquo;t pass positional arguments after keyword argyment.</p>

<p>The flexibility of keyword arguments provides three significant benefits:</p>

<ol>
<li>Functional calls are more clear.</li>
<li>Default arguments defined in function definitions.</li>
<li>Allow extending a function&rsquo;s parameters while it is still backward compatible.</li>
</ol>


<h3>Item 17: Enforce clarity with keyword-only arguments</h3>

<p>In Python 3, you can specify <code>*</code> in the function&rsquo;s argument list.</p>

<pre><code class="plain Keyword-only parameters">&gt;&gt;&gt; def foo(pos, *, forcenamed):
...   print(pos, forcenamed)
... 
&gt;&gt;&gt; foo(pos=10, forcenamed=20)
10 20
&gt;&gt;&gt; foo(10, forcenamed=20)
10 20
&gt;&gt;&gt; foo(10, 20)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: foo() takes exactly 1 positional argument (2 given)
</code></pre>

<p>This can also be combined with <code>**kwargs</code>:</p>

<pre><code class="python">def foo(pos, *, forcenamed, **kwargs):
</code></pre>

<p>In Python 2, the alternative is to <code>pop</code> the <code>**kwargs</code> with default values.
However, that requires docstring to explain what parameters (keys) are expected in <code>kwargs</code> and you lose signature information in your smart editor.</p>

<p>Another alternative in Python 2 is to use a dummy keyword argument to limit number of positional argument.</p>

<pre><code class="python ">_dummy = object()

def foo(pos, _kw=_dummy, forcenamed):
    if _kw is not _dummy:
        raise TypeError("foo() takes 1 positional argument (at least 2 given)")
</code></pre>

<p>This will allow:</p>

<pre><code class="python Examples"># Allowed
foo(bar)        
foo(bar, collapse=0)        
foo(spacing=15, pos=bar)

# But not allowed
foo(bar, 12)
</code></pre>

<p>See <a href="https://stackoverflow.com/questions/2965271/forced-naming-of-parameters-in-python">here</a> for more discussions.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Effective Python Pt. 2: Comprehensions & Generators]]></title>
    <link href="http://tdongsi.github.io/python/blog/2018/08/12/effective-python-part-2/"/>
    <updated>2018-08-12T00:19:30-07:00</updated>
    <id>http://tdongsi.github.io/python/blog/2018/08/12/effective-python-part-2</id>
    <content type="html"><![CDATA[<p>This post corresponds to Lesson 2 &ldquo;Comprehensions &amp; Generators&rdquo; of <a href="https://www.safaribooksonline.com/videos/effective-python/9780134175249">&ldquo;Effective Python&rdquo; course</a>.</p>

<!--more-->


<h3>Item 8: Use list comprehension instead of MAP and FILTER</h3>

<p>List comprehension offers the more intuitive way to transform a list to another list.
Note that in Python 3, the <code>map</code> function now returns an iterator instead of a list like Python 2.
Therefore, you have to add an extra step to convert to a list.</p>

<pre><code class="python List comprehension">a = range(10)
# Recommended
squares = [x**2 for x in a]
# Old way: map in Python 2
squares = map(lambda x: x**2, a)
# Old way: map in Python 3
squares = list(map(lambda x: x**2, a))
print(squares)
</code></pre>

<p>In addition, list comprehension makes it easy to add a condition for filtering.
Using <code>filter</code> and <code>map</code>, it becomes very &ldquo;noisy&rdquo; with multiple enclosing functions and lambdas, as shown below.</p>

<pre><code class="python List comprehension with filtering">b = range(5)
# Recommended
squares = [x**2 for x in b if x % 2 == 0]
# Old way in Python 2
squares = map(lambda x: x**2, filter(lambda x: x % 2 == 0, b))
</code></pre>

<p>Dictionary and set also have similar comprehension expressions for similar purposes.
The final note is that for very complex transformations and filtering that is not easy to pack into comprehension expressions, it is recommended to explicitly use the <code>for</code> loop instead.</p>

<h3>Item 9: Avoid more than two expressions in list comprehensions</h3>

<p>As examples, the transformations of two-dimensional matrices can be done easily with list comprehensions, as follows.</p>

<pre><code class="python Transforming matrices">matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
flatten = [x for row in matrix for x in row]
print(flatten)

squared = [[x**2 for x in row] for row in matrix]
print(squared)
</code></pre>

<p>However, for 3D (or more) matrices, such approach with list comprehensions can be really hard to read.</p>

<pre><code class="python 3D matrix"># 3D matrix
matrix = [
    [[1, 2, 3], [4, 5, 6]],
    [[7, 8, 9], [10, 11, 12]]
]
flatten = [x for sublist1 in matrix
           for sublist2 in sublist1
           for x in sublist2]
print(flatten)
</code></pre>

<p>As shown above, even a simple transformation of matrix flattening can make the code hard to read due to multiple levels of <code>for</code> loops.
Instead of using list comprehensions in those cases, it is recommended to explicitly use <code>for</code> loops when there are more than two expressions in such list comprehensions.</p>

<pre><code class="python 3D matrix"># Recommended way
flatten = []
for sublist1 in matrix:
    for sublist2 in sublist1:
        flatten.extend(sublist2)
print(flatten)
</code></pre>

<p>Another example of abusing list comprehension is to perform multiple filtering operations, such as:</p>

<pre><code class="python Multiple filtering operations">matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
filtered = [[x for x in row if x % 3 == 0]
            for row in matrix if sum(row) &gt;= 10]
print(filtered)
</code></pre>

<p>In this example, the expression performs filtering not only on rows in the matrix but also on elements in rows.
Such expressions are really hard to understand since the code is not read in the natural order of logic and flow of thoughts (see <a href="https://en.wikipedia.org/wiki/Literate_programming">literate programming</a>).
It is recommended to explicitly use <code>for</code> loops for such cases.</p>

<h3>Item 10: Consider generator expressions for large comprehensions</h3>

<p>The problems with list comprehensions are that they may create a whole new list containing all the data.
For large inputs, it can consume a significant amount of memory and can even crash your program.</p>

<p>For a (very contrived) example, let&rsquo;s say you want to return the length of each line in a file and its squares.
You can easily achieve that with the following list comprehensions.</p>

<pre><code class="python List comprehension on a file">value = [len(x) for x in open('/tmp/my_file.txt')]
squares = [(x, x**2) for x in better]
</code></pre>

<p>However, list comprehension on a file like this is very risky.
The file can be really large or even never ending (such as a network socket).
To solve this problem, Python has generator expressions, which are a generalization of comprehensions and generators.
A generator expression gives you an iterator that you can go through that will yield one item at a time from the input and you can determine how many output items you want to return.
The above code can be rewritten as follows:</p>

<pre><code class="python Generator expression">better = (len(x) for x in open('/tmp/my_file.txt'))
roots = ((x, x**0.5) for x in better)
print(next(roots))
print(next(better))
print(next(roots))

### Example Output
[37, 20, 60, 38, 85, 65, 96, 4, 45, 44]
(37, 1369)
20
(60, 3600)
</code></pre>

<p>As you can see, another powerful outcome of using generator expressions is that they can be composed together.
When you call <code>next(roots)</code>, Python goes back up to the generator expression <code>better</code>, then realizes that it has to read another line out of the file.
It has to read the line, then compute its length.
That length value is then passed back to <code>roots</code> as <code>x</code> and for computing the tuple.
What&rsquo;s surprising is that chaining generators like this actually executes very quickly in Python.
When you&rsquo;re looking for a way to compose functionallity that&rsquo;s operating on a large stream of input, generator expressions are one of the best tools for the job.</p>

<h3>Item 11: Consider generator functions instead of returning lists</h3>

<p>Let&rsquo;s say you want to find the index of every single words in a string.
The typical approach will be something as follows:</p>

<pre><code class="python Typical way">def index_words_typical(text):
    result = []
    if text:
        result.append(0)
    for index, letter in enumerate(text):
        if letter == ' ':
            result.append(index+1)
    return result
</code></pre>

<p>The typical approach that returns a list of indices has a problem.
It is dense and noisy with all logistics related to <code>result</code> list: initializing the list, appending to the list whenever a result is found.
A better way to write this function is to use a generator function, with <code>yield</code> statements, as follows:</p>

<pre><code class="python Better way">def index_words(text):
    if text:
        yield 0
    for index, letter in enumerate(text):
        if letter == ' ':
            yield index+1
</code></pre>

<pre><code class="python Equivalent outputs">address = 'The quick brown fox jumps over the lazy dog'
print(list(index_words(address)))
print(index_words_typical(address))

# Output
[0, 4, 10, 16, 20, 26, 31, 35, 40]
[0, 4, 10, 16, 20, 26, 31, 35, 40]
</code></pre>

<p>As you can see, the generator version of this function is much easier to read than the typical version that returns lists.
Most significantly, all of the interactions with the <code>result</code> list have been taken away.
Instead, you just have those <code>yield</code> statements, making it very obvious what is being returned.
That helps make it clear to new readers of the code.</p>

<p>The second problem of the typical approach is that it requires all results to be stored in the lists before being returned.
For huge inputs, this can cause your program to run out of memory and crash.
In contrast, the generator version of the function can handle any amount of output because it doesn&rsquo;t actually keep all of the results in memory that it found.
In the example above, if the input <code>address</code> is a huge text and you only need to display the first hundred indices, the typical approach <code>index_words_typical</code> might fail while the generator version works perfectly fine.</p>

<h3>Item 12: Be defensive when iterating over arguments</h3>

<pre><code class="python Iterator as argument">def normalize_data(numbers):
    total = sum(numbers)
    result = []
    for value in numbers:
        percent = 100.0 * value / total
        result.append(percent)
    return result

def read_visits(data_path):
    with open(data_path) as f:
        for line in f:
            yield int(line)
</code></pre>

<pre><code class="python Testing">path = '/tmp/my_numbers.txt'
with open(path, 'w') as f:
    for i in [15, 80, 35]:
        f.write('%d\n' % i)

print(normalize_data([15, 80, 35]))
print(normalize_data(read_visits(path)))
</code></pre>

<pre><code class="plain Output">[11.538461538461538, 61.53846153846154, 26.923076923076923]
[]
</code></pre>

<p>As you can see from the output, <code>normalize_data</code> works fine with a list of numbers but it does not work when we are supplying an iterator as input.
The main reason is that we iterate multiple times with the input iterator.
After the first traversal for <code>sum</code>, the iterator is already exhausted and that explains an empty list for the output <code>result</code>.</p>

<p>The most straight-forward fix for the function <code>normalize_data</code> is probably to add a line <code>numbers = list(numbers)</code> at the beginning to materialize the iterator.
However, such fix will defeat the purpose of using iterators and the function <code>read_visits</code>: they allow handling a arbitrarily large number of inputs without committing a large working memory.</p>

<p>Another possible fix for the function <code>normalize_data</code> is as folllows:</p>

<pre><code class="python Another fix">def normalize_data_2(get_iter):
    total = sum(get_iter())
    result = []
    for value in get_iter():
        percent = 100.0 * value / total
        result.append(percent)
    return result

get_iter = lambda: read_visits(path)
print(normalize_data_2(get_iter))
</code></pre>

<p>In this approach, we recreate the iterator whenever we need to iterate the data.
So, if we need to traverse twice to normalize the data, we have to call <code>read_visits</code> twice, open the file, and read the data that many times.
The upside is that we have the correct behavior while still retaining the benefits of using iterators.
The problem of this approach is that it is very noisy and hard to read with <code>get_iter</code> and <code>lambda</code>.
A more Pythonic way to do the same thing is to use a container class for the behavior of <code>read_visits</code>, as follows:</p>

<pre><code class="python Converting read_visits to a class">class ReadVisits(object):
    def __init__(self, data_path):
        self.data_path = data_path

    def __iter__(self):
        with open(self.data_path) as f:
            for line in f:
                yield int(line)

visits = ReadVisits(path)
print(normalize_data(visits))
</code></pre>

<p>Here, <code>normalize_data</code> can be the same as before.
The idea is still the same, we recreate the iterator whenever we need to iterate the data.
In the example, when we iterate the <code>numbers</code> for computing <code>sum</code> or in <code>for</code> loop in <code>normalize_data</code> method, we effectively call <code>iter(numbers)</code> to retrieve the iterators.
It is defined in <code>__iter__</code> method, which will open the file and read the data whenver it is called.
However, it is much clearer and more readable than before since we encapsulate the behavior of <code>read_visits</code> method into the class <code>ReadVisits</code>.</p>

<p>Finally, one minor improvement that we can add is to validate if the input argument of <code>normalize_data</code> is a container, as opposed to plain old iterator.
If the argument is a plain old iterator, its data can be exhausted after first traversal and the <code>normalize_data</code> method will not behave correctly.
To check that, a simple check &ldquo;iter(numbers) is iter(numbers)&rdquo; will suffice.
For container-type arguments such as a list or <code>ReadVisits</code> object, each <code>iter</code> call returns a different iterator.</p>
]]></content>
  </entry>
  
</feed>
